#### 经典服务器分发架构

一台前端web服务器，用于分发请求；多台后端服务器，用于处理业务逻辑；

分发逻辑一般是使用请求携带的某个标识作哈细化处理，再模以服务器数量，根据得到的值决定分发到哪台后台服务器；

- 缺点：在新增或减少后端服务器时，数据迁移代价很大；如果每台后端服务器有缓存数据，需要将所有的key模以新的服务器数量，计算出要分发的机器再进行数据迁移，这个代价高且复杂；

#### 一致性哈希

一致性哈希是哈希函数实现的一种分发算法，具体是：

- 哈希函数的输出值是有大小的，可以将哈希函数的输出当做一个首位相连的环处理
- 将后端服务器的某个专属信息作为key进行哈细化，所得到的多个哈希值分别打到哈希输出域的环上
- 所有后端服务器的某个专属信息作为key进行哈细化，所得到的哈希值分别打到哈希函数输出域的环上
- 前端服务器接受一个请求时，将请求的key进行哈希化，由于经过相同的哈希函数处理，所以该哈希值一定是在输出域的环上，该哈希值在环中顺时针的下一个哈希值，就是该请求要分发的后端服务器



#### 如何顺时针的寻找机器

前端服务器保存每台后端服务器key的哈希值，并排序；

寻找一个请求要分发的机器，在该数组上二分的寻找第一个大于该请求哈希值的数，如果没有大于该请求哈希值的数，则选择第一台后端服务器进行分发；

```php
//时间复杂度是O(N)的做法
$array = [200, 150, 100, 90, 70, 10, 5, 1];
$key = 65;

$needed = current($array);
for($i=0; $i<count($array); $i++)
{
    if($array[$i] > $key)
        $needed = $array[$i];
    else
        break;
}
```



#### 数据迁移代价

假设后端原本有3台机器，哈希环是 m1 => m2 => m3 => m1；

现在新增一台服务器m4，哈希环将变为 m1 => m2 => m3 => m4 => m1，数据迁移只需要在m1机器上将m3 => m4这段哈希值所对应的数据迁移到m4机器上；减少服务器数据迁移也是一个道理；

通过一致性哈希算法，数据迁移或者损失的代价非常低。



#### 虚拟节点

初始机器很少的时候，哈希函数的特性无法保证机器是均分整个哈希环的，这会导致负载不均衡虚拟节点的引入是为了解决这种问题；

- 哈希函数的离散性：能将关键字集合K均匀地分布在地址集{0,1，…，m-1}上，使冲突最小。

用虚拟节点替代物理节点，即让每台后端服务器虚拟出N多个虚拟节点并分别分布在整个哈希环上，以虚拟节点代替物理节点；

根据哈希函数的离散性，当输入量比较大的时候是会平均的分布在每个输出域上的，通过虚拟出大量虚拟节点可以保证$X$台机器各占据$1/X$部分哈希域，依次来保证负载均衡。

- 数据缺失计算

  假设有3台机器，每台继续虚拟1万个虚拟节点，大体每天机器负载$1/3$请求的数据；当新增一台新服务器时，每天机器占据$1/4$部分请求数据，可以认为原本3台机器每台少了$1/12$部分数据；

- 虚拟节点落地结构

  机器IP+数字，例如机器1IP加1至10000的后缀字符分别哈希化来表示一万个虚拟节点；前端机器保存虚拟节点，不同的是数组存储的是一个键值对，键是虚拟节点哈希值，值是该节点对应的机器ip。



